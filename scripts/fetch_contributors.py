#!/usr/bin/env python3
"""
Generated by chatgpt and lightly modified by JK

Fetch contributors for a GitHub repo and write a YAML summary:
- github_username
- email address(es) (if available)
- contributions: commits + lines added/deleted (via local git log)

Default repo: tskit-dev/tskit

Requirements:
  pip install requests pyyaml

Usage examples:
  # API-only (commits, and maybe public email; no line stats)
  python github_contribs_to_yaml.py --out tskit_contributors.yaml

  # Full stats (clones repo; computes line +/- from git history)
  python github_contribs_to_yaml.py --use-git --out tskit_contributors.yaml

  # With a GitHub token (recommended to avoid rate limits)
  export GITHUB_TOKEN=ghp_...
  python github_contribs_to_yaml.py --use-git --out tskit_contributors.yaml
"""

from __future__ import annotations

import argparse
import collections
import json
import os
import re
import subprocess
import sys
import tempfile
import time
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Set, Tuple

import requests
import yaml


GITHUB_API = "https://api.github.com"


@dataclass
class ContributorRecord:
    github_username: Optional[str]
    emails: List[str]
    commits: int
    lines_added: int
    lines_deleted: int

    @property
    def lines_net(self) -> int:
        return self.lines_added - self.lines_deleted

    def to_yaml_obj(self) -> dict:
        d = {
            "github_username": self.github_username,
            "emails": sorted(set(self.emails)),
            "commits": int(self.commits),
            "lines_added": int(self.lines_added),
            "lines_deleted": int(self.lines_deleted),
            "lines_net": int(self.lines_net),
        }
        return d


def _gh_headers(token: Optional[str]) -> dict:
    hdrs = {
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
        "User-Agent": "contrib-yaml-script",
    }
    if token:
        hdrs["Authorization"] = f"Bearer {token}"
    return hdrs


def _request_json(
    session: requests.Session,
    url: str,
    token: Optional[str],
    params: dict | None = None,
) -> Tuple[dict | list, requests.Response]:
    resp = session.get(url, headers=_gh_headers(token), params=params, timeout=60)
    # Basic rate-limit friendliness:
    if resp.status_code == 403 and resp.headers.get("X-RateLimit-Remaining") == "0":
        reset = resp.headers.get("X-RateLimit-Reset")
        if reset:
            sleep_for = max(0, int(reset) - int(time.time()) + 5)
            raise RuntimeError(
                f"GitHub rate limit exhausted; reset in ~{sleep_for}s. Use a token (GITHUB_TOKEN)."
            )
    resp.raise_for_status()
    return resp.json(), resp


def _paginate(
    session: requests.Session,
    url: str,
    token: Optional[str],
    params: dict | None = None,
) -> List[dict]:
    """
    Follows GitHub Link headers for pagination.
    Returns list of JSON objects across all pages.
    """
    results: List[dict] = []
    next_url = url
    next_params = dict(params or {})

    while next_url:
        data, resp = _request_json(session, next_url, token, next_params)
        if isinstance(data, list):
            results.extend(data)
        else:
            raise ValueError(
                f"Expected list response for pagination; got {type(data)} from {next_url}"
            )

        link = resp.headers.get("Link", "")
        m = re.search(r'<([^>]+)>;\s*rel="next"', link)
        if m:
            next_url = m.group(1)
            next_params = None  # URL already contains query params
        else:
            next_url = None

    return results


def fetch_contributors(owner: str, repo: str, token: Optional[str]) -> Dict[str, int]:
    """
    Returns {login: commit_count} from /contributors endpoint.
    """
    url = f"{GITHUB_API}/repos/{owner}/{repo}/contributors"
    with requests.Session() as session:
        items = _paginate(
            session, url, token, params={"per_page": 100, "anon": "false"}
        )
    contribs: Dict[str, int] = {}
    for it in items:
        login = it.get("login")
        if not login:
            continue
        contribs[login] = int(it.get("contributions", 0))
    return contribs


def fetch_public_email(login: str, token: Optional[str]) -> Optional[str]:
    """
    Returns the user's public email, if set (often None).
    """
    url = f"{GITHUB_API}/users/{login}"
    with requests.Session() as session:
        data, _ = _request_json(session, url, token)
    email = data.get("email")
    return email if email else None


def fetch_commit_emails_for_author(
    owner: str, repo: str, login: str, token: Optional[str], max_pages: int = 3
) -> Set[str]:
    """
    Attempts to collect commit author emails observed for a GitHub login in this repo.

    Uses:
      GET /repos/{owner}/{repo}/commits?author={login}&per_page=100&page=N

    Notes:
      - commit['commit']['author']['email'] is the git author email for that commit.
      - This may be a noreply address or a real address.
      - We cap pages to avoid excessive API usage.
    """
    emails: Set[str] = set()
    url = f"{GITHUB_API}/repos/{owner}/{repo}/commits"
    with requests.Session() as session:
        for page in range(1, max_pages + 1):
            data, _ = _request_json(
                session,
                url,
                token,
                params={"author": login, "per_page": 100, "page": page},
            )
            if not isinstance(data, list) or len(data) == 0:
                break
            for c in data:
                try:
                    e = c["commit"]["author"]["email"]
                    if e:
                        emails.add(e)
                except Exception:
                    pass
    return emails


def _run(cmd: List[str], cwd: Optional[str] = None) -> str:
    proc = subprocess.run(
        cmd,
        cwd=cwd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        check=False,
    )
    if proc.returncode != 0:
        raise RuntimeError(
            f"Command failed ({proc.returncode}): {' '.join(cmd)}\nSTDERR:\n{proc.stderr}"
        )
    return proc.stdout


def git_clone_and_compute_stats(owner: str, repo: str) -> Dict[str, dict]:
    """
    Clones the repo (history only; blobless where supported) into a temp dir and computes:
      - commits per email
      - lines added/deleted per email
      - observed name(s) per email

    Returns:
      stats[email] = {"commits": int, "add": int, "del": int, "names": set(str)}
    """
    repo_url = f"https://github.com/{owner}/{repo}.git"
    stats: Dict[str, dict] = {}

    with tempfile.TemporaryDirectory(prefix="repo_clone_") as td:
        # Partial clone to reduce download size; still retains history.
        # If your git is old and doesn't support --filter, remove that flag.
        _run(["git", "clone", "--filter=blob:none", "--no-checkout", repo_url, td])

        # 1) commit counts + names/emails from shortlog
        # format: "<count>\t<Name> <email>"
        shortlog = _run(["git", "shortlog", "-sne"], cwd=td)
        for line in shortlog.splitlines():
            line = line.strip()
            if not line:
                continue
            m = re.match(r"^(\d+)\s+(.+)\s+<([^>]+)>$", line)
            if not m:
                continue
            n_commits = int(m.group(1))
            name = m.group(2).strip()
            email = m.group(3).strip()

            rec = stats.setdefault(
                email, {"commits": 0, "add": 0, "del": 0, "names": set()}
            )
            rec["commits"] += n_commits
            rec["names"].add(name)

        # 2) additions/deletions per email by scanning git log --numstat
        # We print the email once per commit (pretty), then numstat lines follow.
        # We'll aggregate all numstat lines until next email marker.
        log_out = _run(
            ["git", "log", "--pretty=format:__EMAIL__%ae", "--numstat"], cwd=td
        )

        current_email: Optional[str] = None
        for line in log_out.splitlines():
            if line.startswith("__EMAIL__"):
                current_email = line[len("__EMAIL__") :].strip()
                if current_email:
                    stats.setdefault(
                        current_email,
                        {"commits": 0, "add": 0, "del": 0, "names": set()},
                    )
                continue
            if not line.strip() or current_email is None:
                continue

            # numstat format: "<add>\t<del>\t<path>" (add/del may be '-' for binaries)
            parts = line.split("\t")
            if len(parts) < 3:
                continue
            a, d = parts[0], parts[1]
            if a == "-" or d == "-":
                continue
            try:
                add_i = int(a)
                del_i = int(d)
            except ValueError:
                continue

            stats[current_email]["add"] += add_i
            stats[current_email]["del"] += del_i

    return stats


def build_records(
    owner: str,
    repo: str,
    token: Optional[str],
    use_git: bool,
    author_email_pages: int,
) -> List[ContributorRecord]:
    contrib_commits = fetch_contributors(owner, repo, token)

    # Start with GitHub contributor logins
    gh_emails: Dict[str, Set[str]] = {login: set() for login in contrib_commits.keys()}

    # Public email (rare)
    for login in list(gh_emails.keys()):
        try:
            e = fetch_public_email(login, token)
            if e:
                gh_emails[login].add(e)
        except Exception:
            # Non-fatal
            pass

    # Commit-observed emails (often noreply)
    for login in list(gh_emails.keys()):
        try:
            observed = fetch_commit_emails_for_author(
                owner, repo, login, token, max_pages=author_email_pages
            )
            gh_emails[login].update(observed)
        except Exception:
            # Non-fatal
            pass

    if not use_git:
        # API-only output
        records: List[ContributorRecord] = []
        for login, commits in sorted(
            contrib_commits.items(), key=lambda x: x[1], reverse=True
        ):
            records.append(
                ContributorRecord(
                    github_username=login,
                    emails=sorted(gh_emails.get(login, set())),
                    commits=int(commits),
                    lines_added=0,
                    lines_deleted=0,
                )
            )
        return records

    # Git-based stats
    git_stats = git_clone_and_compute_stats(owner, repo)

    # Map git emails to GitHub logins using observed commit emails
    email_to_login: Dict[str, str] = {}
    collisions: Dict[str, Set[str]] = collections.defaultdict(set)
    for login, emails in gh_emails.items():
        for e in emails:
            if e in email_to_login and email_to_login[e] != login:
                collisions[e].update({email_to_login[e], login})
            else:
                email_to_login[e] = login

    # Aggregate per login
    per_login_add = collections.Counter()
    per_login_del = collections.Counter()
    per_login_emails: Dict[str, Set[str]] = {
        login: set(emails) for login, emails in gh_emails.items()
    }

    # Unmatched git emails (appear in history but not linked to a GitHub login)
    unmatched_email_stats: Dict[str, dict] = {}

    for email, st in git_stats.items():
        if email in collisions:
            # Ambiguous mapping; treat as unmatched to avoid misattribution
            unmatched_email_stats[email] = st
            continue
        login = email_to_login.get(email)
        if login:
            per_login_add[login] += int(st["add"])
            per_login_del[login] += int(st["del"])
            per_login_emails[login].add(email)
        else:
            unmatched_email_stats[email] = st

    # Build records for GitHub logins
    records: List[ContributorRecord] = []
    for login, commits in sorted(
        contrib_commits.items(), key=lambda x: x[1], reverse=True
    ):
        records.append(
            ContributorRecord(
                github_username=login,
                emails=sorted(per_login_emails.get(login, set())),
                commits=int(commits),
                lines_added=int(per_login_add.get(login, 0)),
                lines_deleted=int(per_login_del.get(login, 0)),
            )
        )

    # Optionally include unmatched historical authors
    # (useful for completeness; can be removed if you only want GitHub accounts)
    for email, st in unmatched_email_stats.items():
        records.append(
            ContributorRecord(
                github_username=None,
                emails=[email],
                commits=int(st.get("commits", 0)),
                lines_added=int(st.get("add", 0)),
                lines_deleted=int(st.get("del", 0)),
            )
        )

    # Sort with GitHub users first, then commits desc
    records.sort(
        key=lambda r: (r.github_username is None, -r.commits, (r.github_username or ""))
    )
    return records


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--owner", default="tskit-dev", help="GitHub org/user (default: tskit-dev)"
    )
    ap.add_argument("--repo", default="tskit", help="GitHub repo name (default: tskit)")
    ap.add_argument("--out", required=True, help="Output YAML file path")
    ap.add_argument(
        "--use-git",
        action="store_true",
        help="Clone repo and compute line +/- from git history",
    )
    ap.add_argument(
        "--author-email-pages",
        type=int,
        default=3,
        help="Max pages to scan per author for commit-observed emails (default: 3)",
    )
    args = ap.parse_args()

    token = os.environ.get("GITHUB_TOKEN")

    records = build_records(
        owner=args.owner,
        repo=args.repo,
        token=token,
        use_git=args.use_git,
        author_email_pages=args.author_email_pages,
    )

    out_obj = {
        "repository": f"{args.owner}/{args.repo}",
        "generated_at_utc": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "note": (
            "GitHub user emails are typically unavailable unless public. "
            "Commit-observed emails may be noreply addresses. "
            "Line +/- counts come from git log --numstat and may differ from GitHub UI."
            if args.use_git
            else "API-only mode: line +/- not computed (set --use-git for git-derived stats)."
        ),
        "contributors": [r.to_yaml_obj() for r in records],
    }

    with open(args.out, "w", encoding="utf-8") as f:
        yaml.safe_dump(out_obj, f, sort_keys=False, allow_unicode=True)

    return 0


if __name__ == "__main__":
    main()
